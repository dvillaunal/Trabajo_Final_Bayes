---
title: "Trabajo Final Bayesiana"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r}
# Librerias y configuraciones iniciales:
library(tidyverse)
library(magrittr)
library(janitor)
library(readr)
library(BayesFactor)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(brms)
```

# Lectura y modificación de la base de datos:

```{r dataset}
df <- read_csv("dataset.csv")
df$assess_c %<>%  as.factor()
df$cancer_c %<>%  as.factor()
df$density_c %<>%  as.factor()
df$famhx_c %<>%  as.factor()

n=dim(df0)[1]
p=dim(df0)[2]

print(paste0("number of observations = ", n))

print(paste0("number of predictors = ", p))
```


# Analisís descriptivo

```{r categoricos}
df$assess_c %>%  table() %>% prop.table() %>% round(2) %>% as.data.frame()
df$cancer_c %>%  table() %>% prop.table() %>% round(2) %>% as.data.frame()
df$density_c %>%  table() %>% prop.table() %>% round(2) %>% as.data.frame()
df$famhx_c %>%  table() %>% prop.table() %>% round(2) %>% as.data.frame()
```


# Creación del modelo base

Aqui se crea el modelo base, es decir, es una construcción con todas las variables de respueta del modelo (previamente tratadas y modificadas según las necesidades apriori de la creación del modelo.) 

```{r model1}
# Modelo logístico binario (Bernoulli), en base de RStan:
# Son 15.000 iteraciones por cadena, con un burning (warmup) de las primeras 3000 iteraciones
# Son 3 cadenas
# se fija una semilla para mantener los resultados
# según el dia o el equipo a correr el modelo
model2 <- brm(formula = cancer_c ~ age_c + assess_c + famhx_c + density_c
              +bmi_c,
              data=df, 
             family = bernoulli(link = "logit"),
             warmup = 3000, 
             iter = 15000, 
             chains = 3, 
             inits= "0", 
             cores=2,
             seed = 123)
```


El modelo nos arroja lo siguiente:

```{r summary}
# Son dos formas de resumen del modelo ajustado:
model2$fit
summary(model2)
```

> Nota: el modelo tomo como indice las primeras catecorias de cada variable categorica.

Aqui podemos que muchas de los parametros no sosn significativos en gran medida, es decir, sus IC son muy cercanos a 0.

Otra cosa a notar es que el Rhat fue de 1 en todos los parametros, por lo que así a grosso modo notamos una convergencia de estos hacia la variable de respuesta.

# Evaluación del modelo

Para evaular este modelo tendremos varias formas, la mayoria son diagnosticos
visuales para una mejor claridad del valor del modelo.

## HDI 

```{r HDI}
name <- paste0("b_",model2[["prior"]][["coef"]])[c(-1,-14)]
color_scheme_set("red")
mcmc_intervals(model2$fit, pars = name)
```

Aqui podemos ver los HDI de los parametros estimados en el modelo.


## Rhat

Dado que el **Rhat** sirve como una medida para observar la convergencia de cada uno de los parametros

```{r rhat}
rhats2 <- rhat(model2)
print(rhats2)

color_scheme_set("brightblue")
mcmc_rhat(rhats2) + yaxis_text(hjust = 1)
```

Como podemos ver no tenemos valores extraños o fuera del valor central 1.

## Neff/N

```{r neff/n}
ratios2 <- neff_ratio(model2)

mcmc_neff(ratios2, size = 2) + yaxis_text(hjust = 1)
```


Estos valores concretos son arbitrarios, ya que no tienen un significado teórico particular, pero una heurística útil es preocuparse por cualquier neff/N inferior a 0,1.

Los tamaños de muestra son mejores en la edad de la paciente, si IMC y sus posibles antecendentes de cancer en familiares de primer grado.

## Trace plot

```{r trace plot}
#Función para graficar todos a la vez:
compare_cp_ncp <- function(cp_plot, ncp_plot, ncol = 2, ...) {
  bayesplot_grid(
    cp_plot, ncp_plot, 
    grid_args = list(ncol = ncol),
    subtitles = c("Model 1", 
                  "Model 2"),
    ...
  )
}
```


```{r}
i  = 6:11
name
color_scheme_set("mix-brightblue-gray")
mcmc_trace(model2, pars = name[i]) + 
  xlab("Post-warmup iteration")
```

Aqui podemos ver como cada iteración cumple con lo esperado, una variación no tan amplia (en la mayoria de parametros, ya que en algunas iteraciones si podemos ver unos picos de mayor amplitud) y el comportamiento de las cadenas es estacionario en todos los graficos, además no vemos divergencias (si fuera así estarian marcadas de rojo), esto lo podemos ver en el siguiente grafico.

## NUTS divergence

```{r nuts divergence}
lp2 <- log_posterior(model2)
np2 <- nuts_params(model2)
color_scheme_set("red")
mcmc_nuts_divergence(np2, lp2)
```

Aqui podemos ver que las cadenas de Markov exploran una curvatura más complicada en la distribución del objetivo.

Para el caso de la probabilidad de aceptación notamos unas colas más finas y un grafico con un tubo en forma de tornado por lo que nos dice que no hubo ratios bajos de aceptación, es decir, no tardo muchas iteraciones en dar saltos, pero en Modelos con algoritmos MCMC son aceptables, dado que la mayoria de las iteraciones mantuvieron convergencias lentas, esto es un modelo muy regular ya que apenas cumple con cabalidad los ratios de aceptación en casi siempre de 1.


> Nos comienzan a dar indicios de el modelo no es el mejor, por lo que dentro de poco, veremos dos propuestas con diferentes 

# ACF

```{r}
mcmc_acf(model2, pars = name[6:11], lags = 10)
```


## Rank plot & Density overlay

> Nota: el trace plot con el rank plot juntos

En el rank plot se tiene que observar que sean uniformes las columnas
para observar si hubo una buena convergencia

*"El de arriba muestra unas cadenas relativamente sanas, ya que los rangos se distribuyen de forma relativamente uniforme (lo que significa que una cadena no tiene valores más altos que otra durante un largo periodo de tiempo)"*

```{r rank plot}
mcmc_rank_hist(model2,pars = name[5:8], ref_line = T)
mcmc_dens_overlay(model2, pars=name[1:6])
```

## Energy plot

Las energías exploradas por una cadena de Markov hamiltoniana pueden utilizarse para visualizar tanto la densidad de transición de energía, $\pi(E|q)$ y la distribución de energía marginal,$\pi(E)$. Cuando estas distribuciones están bien ajustadas, la cadena de Markov hamiltoniana debería funcionar con solidez, pero si la densidad de transiciones de energía es significativamente más estrecha que la distribución de energía marginal, entonces la cadena puede no ser capaz de explorar completamente explorar las colas de la distribución objetivo.

```{r Energy Plot}
mcmc_nuts_energy(np2)
```

# Modelo 3:

Aqui podemos ver como nuestro modelo tienen buenas convergencias y se ajusta de una manera apropiada a la distribución final de los datos, pero sus parametros no son nada significativos por lo que haremos un segundo modelo para porbar si teneiendo todas nuestras variables de manera categorica podremos encontrar mejores resultados en el modelo y el tiempo de ejecución de las iteraciones

```{r transformar}
df$age_c %<>% cut(breaks= 3, include.lowest=T,
                 labels=c("18-40", "41-65", "66-90"))

df$bmi_c %<>% cut(breaks= 3, include.lowest=T,
                 labels=c("Bajo Peso", "Normal", "Obesidad"))
```

```{r modelo 3}
model3 <- brm(formula = cancer_c ~ age_c + assess_c + famhx_c
              + density_c
              +bmi_c,
              data=df,
              family = bernoulli(link = "logit"),
              warmup = 3000, 
              iter = 15000, 
              chains = 3, 
              inits= "0", 
              cores=2,
              seed = 123)
```

Simular los datos de salida

```{r simulado}
fakeData <- function(dataset, digits=2, n=NA, 
  use.names=TRUE, use.levels=TRUE, use.miss=TRUE,
  mvt.method="eigen", het.ML=FALSE, het.suppress=TRUE){

  # This function takes as argument an existing dataset, which 
  # must be either a matrix or a data frame. Each column of the 
  # dataset must consist either of numeric variables or ordered 
  # factors. When one or more ordered factors are included, 
  # then a heterogeneous correlation matrix is computed using 
  # John Fox' polycor package. Pairwise complete observations 
  # are used for all covariances, and the exact pattern of 
  # missing data present in the input is placed in the output,
  # provided a new sample size is not requested. Warnings from
  # the hetcor function are suppressed.

  # Author:   Ryne Estabrook
  # Created:  17 Aug 2010

  require(mvtnorm)
  require(polycor)

  # requires data frame or matrix
  if((is.data.frame(dataset)+is.matrix(dataset))==0){
    warning("Data must be a data frame or matrix")
  }

  # organization
  row <- dim(dataset)[1] # number of rows
  if(is.na(n))(n <- row) # sets unspecified sample size to num rows
  col <- dim(dataset)[2] # number of columns
  del <- is.na(dataset)  # records position of NAs in dataset
  if(n!=row){
    select <- round(runif(n, 0.5, row+.49),0)
    del <- del[select,]
  }
  num <- rep(NA, col)    # see what's not a factor
  ord <- rep(NA, col)    # see what's an ordered factor

  # which columns are numeric (the others are factors)?
  for (i in 1:col){
    num[i] <- is.numeric(dataset[,i])
    ord[i] <- is.ordered(dataset[,i])
  }

  # check for unordered factors
  location <- !(num|ord)
  unorder <- sum(location)

  if(unorder>0)warning(
    paste("Unordered factor detected in variable(s):", 
      names(dataset)[location]
    )
  )

  # if everything is numeric, don't invoke polycor
  if(sum(!num)==0){
    # generate data with rmvnorm
    fake <- rmvnorm(n, 
      apply(dataset, 2, mean, na.rm=TRUE),
      cov(dataset, use="pairwise.complete.obs"),
      mvt.method)

    # round the data to the requested digits
    fake <- round(fake, digits)

    # insert the missing data, if so requested
    if(use.miss==TRUE)(fake[del] <- NA)

    # give the variables names, if so requested
    if(use.names==TRUE)(names(fake) <- names(dataset))

    # return the new data
    return(fake)
  }

  # if there are factors, we start here

  # find the variable means (constrain to zero for factors)
  mixedMeans <- rep(0, col)
  mixedMeans[num] <- apply(dataset[,num], 2, mean, na.rm=TRUE)

  # estimate a heterogeneous correlation matrix
  if (het.suppress==TRUE){
    suppressWarnings(het <- hetcor(dataset, ML=het.ML))
  } else (het <- hetcor(dataset, ML=het.ML))
  mixedCov <- het$correlations

  # make a diagonal matrix of standard deviations to turn the 
  # correlation matrix into a covariance matrix
  stand <- matrix(0, col, col)
  diag(stand) <- rep(1, col)
  diag(stand)[num] <- apply(dataset[,num], 2, sd, na.rm=TRUE)
  # pre and post multiply hetero cor matrix by diagonal sd matrix
  mixedCov <- stand %*% mixedCov %*% stand

  # generate the data
  fake <- as.data.frame(rmvnorm(row, mixedMeans, mixedCov, mvt.method))

  # insert the missing data, if so requested
  if(use.miss==TRUE)(fake[del] <- NA)

  # turn the required continuous variables into factors
  for (i in (1:col)[!num]){
    # the original data for this column
    old <- dataset[,i]
   
    # the new data for this column, omiting NAs
    new <- fake[!is.na(fake[,i]),i]

    # what are the levels of the original factor?
    lev <- levels(old)

    # establish cutpoints in new variable from cdf of old factor
    cut <- cumsum(table(old))/(sum(!is.na(old)))

    # put continuous variable into a matrix, repeating value across columns
    wide <- matrix(new, length(new), length(lev))

    # put the cutpoints in a matrix, repeating the cut point values across rows
    crit <- matrix(quantile(new, cut), length(new), length(lev), byrow=TRUE)

    # for each value (row of the wide matrix), 
    # how many cutpoints is the value greater than?
    # number of cutpoints surpassed=category
    fake[!is.na(fake[,i]),i] <- apply(wide>crit, 1, sum)

    # make it a factor
    fake[,i] <- factor(fake[,i], ordered=TRUE)

    # give the new factor the same levels as the old variable
    if(length(levels(fake[,i]))!=length(lev))message(
      paste("Fewer categories in simulated variable", 
      names(fake)[i], "than in input variable", names(dataset)[i]))
    if(use.levels==TRUE&(length(levels(fake[,i]))==length(lev))){
      levels(fake[,i]) <- lev} else (levels(fake[,i]) <- 1:length(lev))
  }

  # round the data to the requested digits
  fake[,num] <- round(fake[,num], digits)

  # give the variables names, if so requested
  if(use.names==TRUE)(names(fake) <- names(dataset))
  
  # return the new data
  return(fake)
}
```

